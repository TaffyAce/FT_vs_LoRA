{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxBNglBAS1zR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import os\n",
        "\n",
        "\n",
        "def show_info(data):\n",
        "\n",
        "    review_sizes = []\n",
        "    for label, review in data.to_numpy().tolist():\n",
        "        review_sizes.append(len(review))\n",
        "\n",
        "    print('最大长度:', max(review_sizes))\n",
        "    print('最小长度:', min(review_sizes))\n",
        "    print('平均长度:', int(sum(review_sizes) / len(review_sizes)))\n",
        "    print('-' * 50)\n",
        "\n",
        "\n",
        "def demo():\n",
        "    # data = pd.read_csv('ChnSentiCorp_htl_8k/ChnSentiCorp_htl_8k.csv')\n",
        "    data = pd.read_csv('hf://datasets/dirtycomputer/weibo_senti_100k/weibo_senti_100k.csv')\n",
        "    data['label'] = np.where(data['label'] == 1, '好评', '差评')\n",
        "\n",
        "    print('数据标签分布:', Counter(data['label']))\n",
        "    print('-' * 50)\n",
        "\n",
        "    # 去掉太长的评论\n",
        "    data = data[data['review'].apply(lambda x: len(x) > 10 and len(x) < 300)]\n",
        "    show_info(data)\n",
        "\n",
        "    # 原始数数据分割\n",
        "    train_data, test_data  = train_test_split(data, test_size=0.2, stratify=data['label'], random_state=42)\n",
        "\n",
        "    print('原始训练集数量:', train_data.shape)\n",
        "    print('原始测试集数量:', test_data.shape)\n",
        "    print('-' * 50)\n",
        "\n",
        "    # 采样部分数据\n",
        "    sample_num = 5000\n",
        "    train_data = train_data.sample(int(sample_num * 0.8), random_state=42)\n",
        "    test_data  = test_data.sample(int(sample_num * 0.2),  random_state=52)\n",
        "\n",
        "    print('最终训练集数量:', train_data.shape)\n",
        "    print('最终测试集数量:', test_data.shape)\n",
        "\n",
        "    # 数据转换字典\n",
        "    train_data = train_data.to_dict(orient='records')\n",
        "    test_data  = test_data.to_dict(orient='records')\n",
        "\n",
        "    # Create the directory if it doesn't exist\n",
        "    os.makedirs('./weibo_senti_100k', exist_ok=True)\n",
        "\n",
        "    # 数据本地存储\n",
        "    pickle.dump(train_data, open('./weibo_senti_100k/01-训练集.pkl', 'wb'))\n",
        "    pickle.dump(test_data,  open('./weibo_senti_100k/02-测试集.pkl', 'wb'))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    demo()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "import pickle\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    Qwen2Tokenizer,\n",
        "    Qwen2ForCausalLM,\n",
        ")\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def get_dataset(tokenizer):\n",
        "    comm_data = pickle.load(open('./weibo_senti_100k/01-训练集.pkl', 'rb'))\n",
        "    result_data = []\n",
        "    for data in comm_data:\n",
        "        message = [\n",
        "            {'role': 'system', 'content': (\n",
        "                '你是一个专业的情感分类助手。你的任务是对输入的文本进行情感分析，'\n",
        "                '判断其情感倾向并输出 \"好评\" 或 \"差评\" 两个词之一，不要输出任何其他额外的信息或解释。'\n",
        "            )},\n",
        "            {'role': 'user', 'content': data['review']},\n",
        "            {'role': 'assistant', 'content': data['label']}\n",
        "        ]\n",
        "        inputs = tokenizer.apply_chat_template(\n",
        "            message,\n",
        "            add_generation_prompt=False,\n",
        "            tokenize=True\n",
        "        )\n",
        "        result_data.append(inputs)\n",
        "    return result_data\n",
        "\n",
        "def demo():\n",
        "    # 1. 加载模型与分词器\n",
        "    estimator: Qwen2ForCausalLM = AutoModelForCausalLM.from_pretrained(\n",
        "        'Qwen/Qwen2.5-0.5B-Instruct'\n",
        "    ).to(device)\n",
        "    tokenizer: Qwen2Tokenizer = AutoTokenizer.from_pretrained(\n",
        "        'Qwen/Qwen2.5-0.5B-Instruct'\n",
        "    )\n",
        "\n",
        "    # 2. 构造 TrainingArguments：每 100 步记录一次\n",
        "    arguments = TrainingArguments(\n",
        "        output_dir='Qwen2.5-0.5B-Instruct-SFT',\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=4,\n",
        "        num_train_epochs=5,\n",
        "        learning_rate=2e-5,\n",
        "        optim='adamw_torch',\n",
        "        eval_strategy='no',\n",
        "        save_strategy='epoch',\n",
        "        save_total_limit=5,\n",
        "        load_best_model_at_end=False,\n",
        "        fp16=True,\n",
        "\n",
        "        # 日志设置：每 100 步记录一次\n",
        "        logging_strategy='steps',\n",
        "        logging_steps=100,\n",
        "        logging_dir='./logs',\n",
        "    )\n",
        "\n",
        "    # 3. 准备数据与 Trainer\n",
        "    train_data = get_dataset(tokenizer)\n",
        "    trainer = Trainer(\n",
        "        model=estimator,\n",
        "        train_dataset=train_data,\n",
        "        args=arguments,\n",
        "        data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        "    )\n",
        "\n",
        "    # 4. 重置显存峰值 & 计时\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.reset_peak_memory_stats(device)\n",
        "    start_time = time.time()\n",
        "\n",
        "    # 5. 开始训练\n",
        "    trainer.train()\n",
        "\n",
        "    # 6. 训练结束，输出耗时 & 显存峰值\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"训练总时长: {elapsed:.2f} 秒\")\n",
        "    if torch.cuda.is_available():\n",
        "        peak_mem = torch.cuda.max_memory_allocated(device) / (1024 ** 3)\n",
        "        print(f\"显存峰值使用: {peak_mem:.2f} GB\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    torch.cuda.empty_cache()\n",
        "    demo()\n"
      ],
      "metadata": {
        "id": "LI93pfKnS6sZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForCausalLM\n",
        "from transformers import Qwen2Tokenizer\n",
        "from transformers import Qwen2ForCausalLM\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def demo():\n",
        "    model_path = 'Qwen2.5-0.5B-Instruct-SFT/checkpoint-2500'\n",
        "    estimator : Qwen2ForCausalLM= AutoModelForCausalLM.from_pretrained(model_path).to(device)\n",
        "    tokenizer : Qwen2Tokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen2.5-0.5B-Instruct')\n",
        "\n",
        "    system = '你是一个专业的情感分类专家，请对以下文本进行情感分类，并输出 \"好评\" 或 \"差评\" 两个词之一。'\n",
        "\n",
        "    while True:\n",
        "        comment = input('请输入评论内容:')\n",
        "        message = [{'role': 'system', 'content': system}, {'role': 'user', 'content': comment}]\n",
        "        inputs = tokenizer.apply_chat_template(message,\n",
        "                                               add_generation_prompt=True,\n",
        "                                               tokenize=True,\n",
        "                                               return_tensors='pt',\n",
        "                                               return_dict=True).to(device)\n",
        "        inputs_length = len(inputs['input_ids'][0])\n",
        "        with torch.no_grad():\n",
        "            outputs = estimator.generate(**inputs, max_length=512)\n",
        "        output = outputs[0]\n",
        "        y_pred = tokenizer.decode(output[inputs_length:], skip_special_tokens=True).strip()\n",
        "        print('预测标签:', y_pred)\n",
        "        print('-' * 50)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    demo()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "pW_7UNmqVSOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForCausalLM\n",
        "from transformers import Qwen2Tokenizer\n",
        "from transformers import Qwen2ForCausalLM\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "def evaluate(model_path):\n",
        "    # 模型和分词器加载\n",
        "    estimator: Qwen2ForCausalLM = AutoModelForCausalLM.from_pretrained(model_path).to(device)\n",
        "    tokenizer: Qwen2Tokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen2.5-0.5B-Instruct', padding_side='left')\n",
        "    # 加载测试集\n",
        "    test_data = pickle.load(open('weibo_senti_100k/02-测试集.pkl', 'rb'))\n",
        "\n",
        "    # 数据加载器\n",
        "    system = '你是一个专业的情感分类专家，请对以下文本进行情感分类，并输出 \"好评\" 或 \"差评\" 两个词之一。'\n",
        "    def collate_fn(batch_data):\n",
        "        inputs, labels = [], []\n",
        "        for data in batch_data:\n",
        "            message = [{'role': 'system', 'content': system}, {'role': 'user', 'content': data['review']}]\n",
        "            inputs.append(message)\n",
        "            labels.append(data['label'])\n",
        "\n",
        "        inputs = tokenizer.apply_chat_template(inputs,\n",
        "                                               add_generation_prompt=True,\n",
        "                                               tokenize=True,\n",
        "                                               return_tensors='pt',\n",
        "                                               padding=True,\n",
        "                                               return_dict=True)\n",
        "\n",
        "        inputs = { k: v.to(device) for k, v in inputs.items() }\n",
        "        return inputs, labels\n",
        "\n",
        "    dataloader = DataLoader(test_data, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "    # 预测评估\n",
        "    true_labels, pred_labels, wrong = [], [], 0\n",
        "    description = '评估-输出错误: %d'\n",
        "    progress = tqdm(range(len(dataloader)), desc=description % wrong)\n",
        "    for inputs, labels in dataloader:\n",
        "        with torch.no_grad():\n",
        "            outputs = estimator.generate(**inputs, max_length=512)\n",
        "        progress.update()\n",
        "\n",
        "        # 输出解码\n",
        "        for output, input, y_true in zip(outputs, inputs['input_ids'], labels):\n",
        "            y_pred = tokenizer.decode(output[len(input):], skip_special_tokens=True).strip()\n",
        "            if y_pred not in ['好评', '差评']:\n",
        "                wrong += 1\n",
        "                progress.set_description(description % wrong)\n",
        "                continue\n",
        "\n",
        "            pred_labels.append(y_pred)\n",
        "            true_labels.append(y_true)\n",
        "\n",
        "    progress.close()\n",
        "\n",
        "    return np.sum(np.array(true_labels) == np.array(pred_labels)) / len(true_labels)\n",
        "\n",
        "\n",
        "def demo():\n",
        "    model_path = 'Qwen/Qwen2.5-0.5B-Instruct'\n",
        "    acc = evaluate(model_path)\n",
        "    print('模型微调前: %.3f' % acc)\n",
        "\n",
        "    model_path = 'Qwen2.5-0.5B-Instruct-SFT/checkpoint-2500'\n",
        "    acc = evaluate(model_path)\n",
        "    print('模型微调后: %.3f' % acc)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    demo()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NoxeQaxCXA5-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}